{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e647d7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with imports\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff770e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It loads environment variables from a .env file into your process environment (so you can access them with os.getenv(\"VAR_NAME\")).\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cb6be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementing different APIs \n",
    "# we can also use openai api key and Anthropic api key as well\n",
    "\n",
    "gemini_api_key = os.getenv('GEMINI_API_KEY')\n",
    "deepseek_api_key = os.getenv('DEEPSEEK_API_KEY')\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "openrouter_api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "\n",
    "if gemini_api_key:\n",
    "    print(f\"Gemini API key exist and begin with {gemini_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"Gemini API key not set\")\n",
    "\n",
    "if deepseek_api_key:\n",
    "    print(f\"DeepSeek API Key exists and begins {deepseek_api_key[:3]}\")\n",
    "else:\n",
    "    print(\"DeepSeek API Key not set (and this is optional)\")\n",
    "\n",
    "if groq_api_key:\n",
    "    print(f\"Groq API Key exists and begins {groq_api_key[:4]}\")\n",
    "else:\n",
    "    print(\"Groq API Key not set (and this is optional)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ce0dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Please come up with a challenging, nuanced question that I can ask a number of LLMs to evaluate their intelligence. \"\n",
    "prompt += \"Answer only with the question, no explanation.\"\n",
    "messages = [{\"role\": \"user\", \"content\": prompt}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2d4942",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ba4bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini = OpenAI(api_key = gemini_api_key, base_url = \"https://generativelanguage.googleapis.com/v1beta/openai/\")\n",
    "response = gemini.chat.completions.create(model = \"gemini-2.0-flash\",messages = messages)\n",
    "\n",
    "question = response.choices[0].message.content\n",
    "print(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5658fcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models = []\n",
    "answers = []\n",
    "messages = [{\"role\":\"user\",\"content\":question}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0b1377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first model e.g \"gemini-2.0-flash\"\n",
    "\n",
    "model_name = \"gemini-2.0-flash\"\n",
    "\n",
    "response = gemini.chat.completions.create(model = model_name, messages = messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "all_models.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd089ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd model e.g Groq(llama-3.3-70b-versatile)\n",
    "groq = OpenAI(api_key=groq_api_key, base_url=\"https://api.groq.com/openai/v1\")\n",
    "model_name = \"llama-3.3-70b-versatile\"\n",
    "\n",
    "response = groq.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "all_models.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e917ae78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3rd model e.g Deppseek()\n",
    "deepseek = OpenAI(api_key=openrouter_api_key, base_url=\"https://openrouter.ai/api/v1\")\n",
    "model_name = \"deepseek/deepseek-chat-v3.1:free\"\n",
    "\n",
    "response = deepseek.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "all_models.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3177d482",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_models)\n",
    "print(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc561ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for competitor, answer in zip(all_models, answers):\n",
    "#     print(f\"Competitor: {competitor}\\n\\n{answer}\")\n",
    "for model,answer in zip(all_models, answers):\n",
    "    print(f\"model: {model}\\n\\nResponse: {answer}\\n{'-'*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741896bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_prompt = f\"\"\"\n",
    "You are judging a competition between {len(all_models)} models.\n",
    "I asked the question: \"{question}\"\n",
    "\n",
    "Here are the answers:\n",
    "\n",
    "- {all_models[0]}: {answers[0]}\n",
    "- {all_models[1]}: {answers[1]}\n",
    "- {all_models[2]}: {answers[2]}\n",
    "\n",
    "Your job is to evaluate each response for clarity and strength of argument, and rank them in order of best to worst.\n",
    "\n",
    "Respond with JSON only, no extra text, using this exact format:\n",
    "{{\"ranking\": [\"best model name\", \"second best model name\", \"third best model name\"]}}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb17d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(eval_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4638cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "judge_messages = [{\"role\": \"user\", \"content\": eval_prompt}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9f5cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Judgement time!\n",
    "\n",
    "model_name = \"gemini-2.0-flash\"\n",
    "\n",
    "response = gemini.chat.completions.create(model = model_name, messages = judge_messages)\n",
    "result = response.choices[0].message.content\n",
    "\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents_foundation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
